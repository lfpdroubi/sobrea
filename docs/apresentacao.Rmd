---
title: "Avaliação através da moda, média ou mediana"
subtitle: "Uma nova abordagem"
author: 
 - "Luiz Fernando Palin Droubi"
 - "Norberto Hochheim"
 - "Willian Zonato"
date: "`r format(Sys.Date(), '%d/%m/%Y')`"
output:
  xaringan::moon_reader:
    yolo: false
    lib_dir: libs
    self_contained: TRUE
    chakra: libs/remark-latest.min.js
    nature:
      countdown: 30000
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
    css: ["default", "estilo.css"]
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(appraiseR)
library(quantreg)
library(texreg)
library(latex2exp)
library(leaflet)
library(sp)
library(ggplot2)
library(emo)
library(reshape2)
theme_set(theme_bw())
```

background-image: url(https://raw.githubusercontent.com/lfpdroubi/dist_lognormal/master/images/densidade_medidas-1.png)

---
class: inverse, center, middle
# ESTIMADORES

---

## Exemplo

Sejam X e Y duas amostras de alturas de homens (X) e mulheres (Y). Assuma, por simplicidade que $\sigma_X = \sigma_Y = \sigma$ e que a médias das populações sejam iguais a $\mu_X$ e $\mu_Y$.

--

Suponha que, baseado nas amostras disponíveis, se pretenda estimar a altura de um homem qualquer na população.

--

A escolha natural seria: $T_1 = \bar{X}$

--

Porém, se a amostragem for pequena, poderíamos utilizar: $T_2 = \frac{\bar{X} + \bar{Y}}{2}$

--

Embora se saiba que $T_2$ é enviesada (mulheres são, em média, menores), temos:

--

* Viés de $T_1$: $\text{B}(T_1) = 0$
* Viés de $T_2$: $B(T_2) = (0,5\mu_1 + 0,5\mu_2)-\mu_1$
* Variância de $T_1$: $\text{Var}(T_1) = \sigma^2/n$
* Variância de $T_2$: $\text{Var}^(T_2) = \text{Var}(0,5\bar{X} + 0,5\bar{Y}) = 0,5^2 \text{Var}(\bar{X}) + 0,5^2 \text{Var}(\bar{Y}) = \sigma^2/2n$

--

Como $\text{MSE}(\theta) = \text{Var}(\theta) + B^2(\theta)$:

* $\text{MSE}(T_1) = \sigma^2/n + 0^2 = \sigma^2/n$
* $\text{MSE}(T_2) = \sigma^2/2n + \left ( (0,5\mu_1 + 0,5\mu_2)-\mu_1 \right )^2 = \sigma^2/2n + \left ( \frac{\mu_2 - \mu_1}{2} \right )^2$

---

Como $\text{MSE}(\theta) = \text{Var}(\theta) + B^2(\theta)$:

* $\text{MSE}(T_1) = \sigma^2/n + 0^2 = \sigma^2/n$
* $\text{MSE}(T_2) = \sigma^2/2n + \left ( (0,5\mu_1 + 0,5\mu_2)-\mu_1 \right )^2 = \sigma^2/2n + \left ( \frac{\mu_2 - \mu_1}{2} \right )^2$

--

Portanto, $T_1$ somente será um melhor estimador que $T_2$ se:

$$\left ( \frac{\mu_2 - \mu_1}{2} \right )^2 > \frac{\sigma^2}{2n}$$

---

Analogamente:

--

* $\text{Var}(\nu) = \text{Var}(\exp(W))$

--

* $\text{B}(\nu) = \nu - \mu  = \frac{\mu}{\exp(\sigma^2/2)} - \mu$

--

* $\text{Var}(\mu) = \text{Var}(\exp(W + \sigma^2/2)) = \text{Var}(\exp(W) .\exp(\sigma^2/2)) = \exp(\sigma^2)\text{Var}(\nu)$

--

* $B(\mu) = 0$

--

Então:

--

$\text{MSE}(\nu) = \text{Var}(\nu) + \text{B}^2(\nu) = \text{Var}(\nu) + \left ( \frac{\mu}{\exp(\sigma^2/2)} - \mu \right )^2$

--

$\text{MSE}(\mu) = \text{Var}(\mu) + \text{B}^2(\mu) = \exp(\sigma^2)\text{Var}(\nu)$

--

Logo, $\mu$ é um estimador melhor que $\nu$ se:

$\text{Var}(\nu) + \left ( \frac{\mu}{\exp(\sigma^2/2)} - \mu \right )^2 > \exp(\sigma^2)\text{Var}(\nu)$

---

$$\text{Var}(\nu) = \text{Var}[\exp(W)]$$


$$\text{Var}(\mu) = \text{Var} \left [ \exp \left ( W + \frac{\sigma^2}{2} \right ) \right ]$$
Como $\text{Var}(c.U) = c^2 \text{Var}(U)$,

$$\text{Var}(\mu) = \text{Var} \left [ \exp(W) . \exp \left ( \frac{\sigma^2}{2} \right ) \right ] = \exp^2 \left ( \frac{\sigma^2}{2} \right ).\text{Var}[\exp(W)] = \exp(\sigma^2).\text{Var}[\exp(W)]$$

---
class: inverse, center, middle

# Distribuição Lognormal

## Definição e propriedades

---

# Distribuição Lognormal

## Definição

Uma variável aleatória $X$ tem distribuição lognormal se seu logaritmo $Y = log(X)$ tem  distribuição normal.

$$f(x;\mu, \sigma) = \frac{1}{x\sigma\sqrt{2\pi}} \exp \left [ -\frac{(\ln(x) - \mu)^2}{2\sigma^2} \right ] $$

em que:

- $\mu$ é a mediana
- $\sigma > 0$ é o desvio-padrão

---

# Estimação dos parâmetros da distribuição

$$\bar{x}^* = \exp \left ( \frac{1}{n} \sum_{i=1}^{n} \ln(x_i) \right ) = \left ( \prod_{i=1}^{n} x_i \right )^{\frac{1}{n}}$$
--

$$s^* = \exp \left \{ \left [ \frac{1}{n-1} \sum_{i=1}^n \left [  \ln \left ( \frac{x_i}{\bar{x}^*}  \right ) \right ] ^2  \right ] ^\frac{1}{2} \right \}$$
---
# Distribuição Lognormal

## Valores comuns de $s^*$

$$1,4 \leq s^* \leq 3$$
## Valores extremos de $s^*$

$$1,1 \leq s^* \leq 33$$

---

# Distribuição Lognormal

## Efeito de $\sigma$ na forma da distribuição

```{r logs, echo = FALSE, dev='svg', fig.height=4}
x <- seq(0, 3, 0.01)
sigma <- c(2, 1.5, 1, .5, .25)
y <- lapply(sigma, dlnorm, x = x, meanlog = log(1))
data <- data.frame(x, y[[1]], y[[2]], y[[3]], y[[4]], y[[5]])
colnames(data) <- c("x", "y1", "y2", "y3", "y4", "y5")
data <- melt(data, id = 1)
ggplot(data, aes(x = x, y = value, 
                 color = factor(variable, labels = as.character(sigma)))) +
  geom_line() +
  scale_y_continuous(limits = c(0, max(data$value)), expand = c(0, 0)) + 
  scale_x_continuous(limits = c(0, max(data$x)), expand = c(0, 0)) +
  labs(title = "Distribuições lognormais",
       subtitle = TeX("$\\mu = log(1) = 0$"),
       color = TeX("$\\sigma$"))
```

---

# Estimativas

--

- O valor esperado (**média**) de $X$ é:

$$E(X) = E(exp(Y)) = exp(E(Y) + 0,5\sigma^2)$$
$$ E(x) = exp(\mu + 0,5\sigma^2)$$
--

- O valor da **mediana** é:

$$\nu=exp(\mu)$$
--

- O valor da **moda** é:

$$M_o=exp(\mu-\sigma^2)$$



---

# Estimativas em função de $\hat{\sigma}$

![Estimativas](estimativas.png)

---

# Regressão linear clássica

### Origem

> The word “regression” is an allusion to the famous comment of Sir Francis Galton in the late 1800s regarding “regression toward the mean.” This referred to the fact that tall parents tend to have children who are less tall closer to the mean – with a similar statement for short parents. The predictor variable here might be, say, the father’s height F, with the response variable being, say, the son’s height S. Galton was saying that E(S|F) < F.

### Definição precisa

$$m_{Y ;X}(t) = \mathbb{E}(Y |X = t)$$
### Notação

$$\mu(t) = \beta_0 + \beta_1t_1 + ... + \beta_pt_p$$

$$\epsilon = Y - \mu(X)$$

$$Y = \beta_0 + \beta_1t_1+ ... +\beta_pt_p+\epsilon$$

???

MATLOFF, N. S. From Algorithms to Z-Scores: Probabilistic and statistical modeling in computer science. Davis, California: Orange Grove Books, 2009.

p. 386

[ProbStatBook](http://heather.cs.ucdavis.edu/~matloff/132/PLN/probstatbook/ProbStatBook.pdf)

---

# $\mu(t)$ minimiza MSPE

## Prova

1. c constante.

$$\mathbb{E}[(W - c)^2] = E[W^2-2cW+c^2] = E(W^2) - 2cE[W]+c^2$$

$$\frac{d \mathbb{E}[(W - c)^2]}{dc} = 0\rightarrow 2E[W] + 2c = 0$$

$$\Leftrightarrow c = E[W]$$

2. $c = f(X)$

$$MSPE = \mathbb{E}[(Y-f(X))^2] = \mathbb{E}[\mathbb{E}[(Y-f(X))^2|X]$$
A função $f(X)$ que minimiza $\mathbb{E}[(Y-f(X))^2]$, por analogia ao item anterior, é a função $E(Y|X)$, ou seja, a média, *i.e.* $\mu(t)$. Então, a expectativa total $\mathbb{E}[\mathbb{E}[(Y-f(X))^2|X]$, também é minimizada com este valor.

---

# Regressão à mediana

$$\mathbb{E}[|Y - m|] = \int_{-\infty}^{\infty}|t-m|f_Y(t)dt$$
Pode-se provar que o valor que minimiza $\mathbb{E}[|Y - m|]$ é a $mediana(Y)$.

---

# Regressão à moda



---

# Exemplo

*Florianópolis -- Centro 2015

```{r, echo = FALSE, out.width='100%', fig.height=6, eval=require('leaflet')}
data(centro_2015)
centro_2015 <- spTransform(centro_2015, CRS("+init=epsg:4326"))
leaflet(centro_2015) %>% 
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addCircleMarkers(color = ~ifelse(padrao == "baixo", "green", 
                                   ifelse(padrao == "medio", "blue", "red")),
                   radius = ~10*as.vector(scale(valor)),
                   popup = as.character(1:50),
                   label = as.character(1:50),
                   fillOpacity = 0.5)
```

---

```{r, echo = FALSE, warning=FALSE}
dados <- centro_2015@data
dados$padrao <- as.numeric(dados$padrao)
fit <- lm(log(valor) ~ area_total + quartos + suites + garagens + 
            log(dist_b_mar) + I(padrao^-1), 
          data = dados)
mfit <- rq(log(valor) ~ area_total + quartos + suites + garagens + 
             log(dist_b_mar) + + I(padrao^-1), 
           data = dados, tau = 0.5)
s <- summary(fit)
```

```{r, echo = FALSE, results='asis', warning=FALSE}
htmlreg(list(fit, mfit), doctype = FALSE,
        single.row = TRUE, 
        include.bic = TRUE,
        caption.above = TRUE, digits = 3,
        ci.force = TRUE)
```

---
class: middle, center, inverse

# Estimativas

```{r, echo = FALSE}
p <- predict(fit)
pm <- predict(mfit)
```

---

# OLS - Moda

```{r, echo = FALSE, dev='CairoSVG', fig.show="hold", fig.height=5}
par(mar = c(5,5,4,2))
plot(exp(fit$fitted.values - s$sigma^2) ~ exp(fit$model[, 1]), 
     xlim = c(0, 3500000), ylim = c(0, 3500000),
     ylab = TeX("\\hat{Y}_{moda}"), xlab = "Y", pch = 19, cex = .75,
     main = "Estimação pela moda")
abline(0, 1)
abline(lm(exp(fit$fitted.values - s$sigma^2) ~ exp(fit$model[, 1])), lty = 2)
```

---

# OLS - Mediana

```{r, echo = FALSE, dev='CairoSVG', fig.show="hold", fig.height=5}
par(mar = c(5,5,4,2))
plot(exp(fit$fitted.values) ~ exp(fit$model[, 1]), 
     xlim = c(0, 3500000), ylim = c(0, 3500000),
     ylab = TeX("\\hat{Y}_{mediana}"), xlab = "Y", pch = 19, cex = .75,
     main = "Estimação pela mediana")
abline(0, 1)
abline(lm(exp(fit$fitted.values) ~ exp(fit$model[, 1])), lty = 2)
```


---

# OLS - Média

```{r, echo = FALSE, dev='CairoSVG', fig.show="hold", fig.height=5}
par(mar = c(5,5,4,2))
plot(exp(fit$fitted.values + .5*s$sigma^2) ~ exp(fit$model[, 1]), 
     xlim = c(0, 3500000), ylim = c(0, 3500000),
     ylab = TeX("\\hat{Y}_{media}"), xlab = "Y", pch = 19, cex = .75,
     main = "Estimação pela média")
abline(0, 1)
abline(lm(exp(fit$fitted.values + .5*s$sigma^2) ~ exp(fit$model[, 1])), lty = 2)
```


---
# QR

```{r, echo = FALSE,  dev='CairoSVG', fig.height=5}
par(mar = c(5,5,4,2))
plot(exp(mfit$fitted.values) ~ exp(mfit$model[, 1]), 
     xlim = c(0, 3500000), ylim = c(0, 3500000),
     ylab = TeX("\\hat{Y}_{mediana}"), xlab = "Y", pch = 19, cex = .75,
     main = "Estimação pela regressão à mediana")
abline(0,1)
abline(lm(exp(mfit$fitted.values) ~ exp(mfit$model[,1])), lty = 2)
```

---

`r emo::ji("money")`

---
class: center, bottom, inverse

# More info

--

Slides created via the R package [**xaringan**](https://github.com/yihui/xaringan).

--

The chakra comes from [remark.js](https://remarkjs.com), [**knitr**](https://yihui.name/knitr), and [R Markdown](https://rmarkdown.rstudio.com).

--

You can read the HTML source of this presentation to learn how it was built.

--

Or check out the R Markdown source at http://slides.yihui.name/xaringan/incremental.Rmd.

--

Have fun.

--

.

--

.

--

.

--

.

--

.

--

THE END
